{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Annisa\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; \n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wbc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 683 entries, 0 to 682\n",
      "Data columns (total 11 columns):\n",
      "index                 683 non-null int64\n",
      "clump_thickness       683 non-null int64\n",
      "cell_size             683 non-null int64\n",
      "cell_shape            683 non-null int64\n",
      "marginal_adhesion     683 non-null int64\n",
      "epitelial_cellsize    683 non-null int64\n",
      "bare_nuclei           683 non-null int32\n",
      "bland_chromatin       683 non-null int64\n",
      "normal_nucleoli       683 non-null int64\n",
      "mitoses               683 non-null int64\n",
      "jenis                 683 non-null int64\n",
      "dtypes: int32(1), int64(10)\n",
      "memory usage: 56.1 KB\n"
     ]
    }
   ],
   "source": [
    "df=df[df.bare_nuclei!='?']\n",
    "df=df.reset_index()\n",
    "df['bare_nuclei']=df['bare_nuclei'].astype(object).astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop([df.columns[-1]], axis=1)\n",
    "y = df.jenis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size=0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9709 (+/-0.048) for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.9709 (+/-0.048) for {'learning_rate': 0.1, 'n_estimators': 75}\n",
      "0.9643 (+/-0.049) for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.9643 (+/-0.049) for {'learning_rate': 0.1, 'n_estimators': 150}\n",
      "0.9643 (+/-0.049) for {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.94      0.99      0.96       142\n",
      "          4       0.97      0.89      0.93        84\n",
      "\n",
      "avg / total       0.95      0.95      0.95       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [50,75,100,150,200],\n",
    "                     'learning_rate': [ 0.1]},]\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters, cv=cv, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters1a = [{'n_estimators': [40,45,50]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9692 (+/-0.047) for {'n_estimators': 40}\n",
      "0.9692 (+/-0.047) for {'n_estimators': 45}\n",
      "0.9709 (+/-0.048) for {'n_estimators': 50}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.94      0.99      0.96       142\n",
      "          4       0.97      0.89      0.93        84\n",
      "\n",
      "avg / total       0.95      0.95      0.95       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate':0.1,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf1a = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters1a, cv=cv, scoring='%s_macro' % score)\n",
    "    clf1a.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf1a.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf1a.cv_results_['mean_test_score']\n",
    "    stds = clf1a.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf1a.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred1a = y_test, clf1a.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred1a))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_estimator terbaik 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 3, 'min_child_weight': 6}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9643 (+/-0.049) for {'max_depth': 3, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 3, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 3, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 3, 'min_child_weight': 12}\n",
      "0.9643 (+/-0.049) for {'max_depth': 5, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 5, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 5, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 5, 'min_child_weight': 12}\n",
      "0.9643 (+/-0.049) for {'max_depth': 7, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 7, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 7, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 7, 'min_child_weight': 12}\n",
      "0.9643 (+/-0.049) for {'max_depth': 9, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 9, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 9, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 9, 'min_child_weight': 12}\n",
      "0.9643 (+/-0.049) for {'max_depth': 11, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 11, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 11, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 11, 'min_child_weight': 12}\n",
      "0.9643 (+/-0.049) for {'max_depth': 13, 'min_child_weight': 6}\n",
      "0.9628 (+/-0.057) for {'max_depth': 13, 'min_child_weight': 8}\n",
      "0.9579 (+/-0.065) for {'max_depth': 13, 'min_child_weight': 10}\n",
      "0.9548 (+/-0.047) for {'max_depth': 13, 'min_child_weight': 12}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "tuned_parameters2 = [{'max_depth': range(3,14,2), \n",
    "                     'min_child_weight': range(6,14,2)},]\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf2 = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters2, cv=cv, scoring='%s_macro' % score)\n",
    "    clf2.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf2.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf2.cv_results_['mean_test_score']\n",
    "    stds = clf2.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf2.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred2 = y_test, clf2.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hasil ideal min_child_weight = 6 max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_parameters2a = [{'max_depth':[2,3,4] ,\n",
    "                     'min_child_weight': [5,6,7]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 2, 'min_child_weight': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9676 (+/-0.053) for {'max_depth': 2, 'min_child_weight': 5}\n",
      "0.9643 (+/-0.049) for {'max_depth': 2, 'min_child_weight': 6}\n",
      "0.9643 (+/-0.049) for {'max_depth': 2, 'min_child_weight': 7}\n",
      "0.9643 (+/-0.049) for {'max_depth': 3, 'min_child_weight': 5}\n",
      "0.9643 (+/-0.049) for {'max_depth': 3, 'min_child_weight': 6}\n",
      "0.9595 (+/-0.052) for {'max_depth': 3, 'min_child_weight': 7}\n",
      "0.9643 (+/-0.049) for {'max_depth': 4, 'min_child_weight': 5}\n",
      "0.9643 (+/-0.049) for {'max_depth': 4, 'min_child_weight': 6}\n",
      "0.9595 (+/-0.052) for {'max_depth': 4, 'min_child_weight': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf2a = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters2a, cv=cv, scoring='%s_macro' % score)\n",
    "    clf2a.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf2a.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf2a.cv_results_['mean_test_score']\n",
    "    stds = clf2a.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf2a.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred2a = y_test, clf2a.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred2a))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_depth merupakan kedalaman dari tree, meningkatkan nilai max_Depth akan membuat model lebih complex/overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters3 = {'gamma':[i/10.0 for i in range (0,5)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gamma itu langrangian multiplier (complexity control)\n",
    "higher gamma = lower difference between train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9676 (+/-0.053) for {'gamma': 0.0}\n",
      "0.9676 (+/-0.053) for {'gamma': 0.1}\n",
      "0.9676 (+/-0.053) for {'gamma': 0.2}\n",
      "0.9676 (+/-0.053) for {'gamma': 0.3}\n",
      "0.9676 (+/-0.053) for {'gamma': 0.4}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 2, \n",
    "    'min_child_weight': 5,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf3 = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters3, cv=cv, scoring='%s_macro' % score)\n",
    "    clf3.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf3.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf3.cv_results_['mean_test_score']\n",
    "    stds = clf3.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf3.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred3 = y_test, clf3.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gamma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters4 = [{'subsample':[i/10.0 for i in range(6,10)] ,\n",
    "                     'colsample_bytree':[i/10.0 for i in range(6,10)]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9645 (+/-0.053) for {'colsample_bytree': 0.6, 'subsample': 0.6}\n",
      "0.9675 (+/-0.035) for {'colsample_bytree': 0.6, 'subsample': 0.7}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.6, 'subsample': 0.9}\n",
      "0.9645 (+/-0.053) for {'colsample_bytree': 0.7, 'subsample': 0.6}\n",
      "0.9659 (+/-0.042) for {'colsample_bytree': 0.7, 'subsample': 0.7}\n",
      "0.9628 (+/-0.057) for {'colsample_bytree': 0.7, 'subsample': 0.8}\n",
      "0.9676 (+/-0.053) for {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "0.9628 (+/-0.051) for {'colsample_bytree': 0.8, 'subsample': 0.6}\n",
      "0.9627 (+/-0.054) for {'colsample_bytree': 0.8, 'subsample': 0.7}\n",
      "0.9564 (+/-0.057) for {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.8, 'subsample': 0.9}\n",
      "0.9660 (+/-0.039) for {'colsample_bytree': 0.9, 'subsample': 0.6}\n",
      "0.9579 (+/-0.050) for {'colsample_bytree': 0.9, 'subsample': 0.7}\n",
      "0.9564 (+/-0.057) for {'colsample_bytree': 0.9, 'subsample': 0.8}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.9, 'subsample': 0.9}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 2, \n",
    "    'min_child_weight': 5,\n",
    "    'gamma':0.0,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf4 = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters4, cv=cv, scoring='%s_macro' % score)\n",
    "    clf4.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf4.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf4.cv_results_['mean_test_score']\n",
    "    stds = clf4.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf4.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred4 = y_test, clf4.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters4a = [{'subsample':[i/100.0 for i in range(85,100,5)] ,\n",
    "                     'colsample_bytree':[i/100.0 for i in range(65,80,5)]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.65, 'subsample': 0.85}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.65, 'subsample': 0.9}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.65, 'subsample': 0.95}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.7, 'subsample': 0.85}\n",
      "0.9676 (+/-0.053) for {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "0.9612 (+/-0.047) for {'colsample_bytree': 0.7, 'subsample': 0.95}\n",
      "0.9643 (+/-0.049) for {'colsample_bytree': 0.75, 'subsample': 0.85}\n",
      "0.9676 (+/-0.053) for {'colsample_bytree': 0.75, 'subsample': 0.9}\n",
      "0.9612 (+/-0.047) for {'colsample_bytree': 0.75, 'subsample': 0.95}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 2, \n",
    "    'min_child_weight': 5,\n",
    "    'gamma':0.0,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf4a = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters4a, cv=cv, scoring='%s_macro' % score)\n",
    "    clf4a.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf4a.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf4a.cv_results_['mean_test_score']\n",
    "    stds = clf4a.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf4a.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred4a = y_test, clf4a.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred4a))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hasilnya tetap sama yaitu colsample_bytee=0.7 , subsample =0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters5 = {'reg_alpha':[1e-5,1e-4,1e-3,1e-2,0.1,1,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'reg_alpha': 1e-05}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 1e-05}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.0001}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.001}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.01}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.1}\n",
      "0.9645 (+/-0.053) for {'reg_alpha': 1}\n",
      "0.5000 (+/-0.000) for {'reg_alpha': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 2, \n",
    "    'min_child_weight': 5,\n",
    "    'gamma':0.0,\n",
    "    'colsample_bytree':0.7,\n",
    "    'subsample':0.9,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf5 = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters5, cv=cv, scoring='%s_macro' % score)\n",
    "    clf5.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf5.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf5.cv_results_['mean_test_score']\n",
    "    stds = clf5.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf5.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred5 = y_test, clf5.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters5a = {'reg_alpha':[0.005,1e-05,0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'reg_alpha': 0.005}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.005}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 1e-05}\n",
      "0.9676 (+/-0.053) for {'reg_alpha': 0.01}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.95      0.99      0.97       142\n",
      "          4       0.97      0.90      0.94        84\n",
      "\n",
      "avg / total       0.96      0.96      0.96       226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "#digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(df)\n",
    "\n",
    "                    \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 2, \n",
    "    'min_child_weight': 5,\n",
    "    'gamma':0.0,\n",
    "    'colsample_bytree':0.7,\n",
    "    'subsample':0.9,\n",
    "    'silent': 1\n",
    "}\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf5a = GridSearchCV(estimator=XGBClassifier(**params_fixed, seed=random_state),\n",
    "    param_grid=tuned_parameters5a, cv=cv, scoring='%s_macro' % score)\n",
    "    clf5a.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf5a.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf5a.cv_results_['mean_test_score']\n",
    "    stds = clf5a.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf5a.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred5a = y_test, clf5a.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred5a))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dengan scores recall yang sama dengan 1e-05, reg alpha yang baru yaitu 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5a.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_all=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "       gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_all.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.9558\n",
      "Precision: 0.9744\n",
      "Recall: 0.9048\n",
      "F1: 0.9383\n"
     ]
    }
   ],
   "source": [
    "y_pred_all = xgb_all.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_all)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_all)\n",
    "print (('Akurasi: %.4f') % (accuracy))\n",
    "print (('Precision: %.4f') % (precision[1]))\n",
    "print (('Recall: %.4f') % (recall[1]))\n",
    "print (('F1: %.4f') % (f1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_all2=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "       gamma=0.0, learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0.0, learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_all2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.9602\n",
      "Precision: 0.9630\n",
      "Recall: 0.9286\n",
      "F1: 0.9455\n"
     ]
    }
   ],
   "source": [
    "y_pred_all2 = xgb_all2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_all2)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_all2)\n",
    "print (('Akurasi: %.4f') % (accuracy))\n",
    "print (('Precision: %.4f') % (precision[1]))\n",
    "print (('Recall: %.4f') % (recall[1]))\n",
    "print (('F1: %.4f') % (f1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# increase learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0.0, learning_rate=0.15, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_all3=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "       gamma=0.0, learning_rate=0.15, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=5, missing=None, n_estimators=50, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0.005, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=42, silent=1, subsample=0.9)\n",
    "xgb_all3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.9469\n",
      "Precision: 0.9737\n",
      "Recall: 0.8810\n",
      "F1: 0.9250\n"
     ]
    }
   ],
   "source": [
    "y_pred_all3 = xgb_all3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_all3)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_all3)\n",
    "print (('Akurasi: %.4f') % (accuracy))\n",
    "print (('Precision: %.4f') % (precision[1]))\n",
    "print (('Recall: %.4f') % (recall[1]))\n",
    "print (('F1: %.4f') % (f1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ternyata akurasi turun, jadi yang terbaik itu xgb_all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoQAAAFlCAYAAAByR/n1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf8Oa6LQsGPrlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa46c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xgb_all2,importance_type='gain',xlabel='Information Gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
