{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfA = pd.read_csv(\"wbc.csv\")\n",
    "dfA=dfA.replace('?',np.nan)\n",
    "dfA['bare_nuclei'] = pd.to_numeric(dfA.bare_nuclei.fillna(dfA.bare_nuclei.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dfA.drop([dfA.columns[-1]], axis=1)\n",
    "y = dfA.jenis.map({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAND_SEED_SPLIT = RAND_SEED_TUNING = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state=RAND_SEED_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "svc=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_range= [2**i for i in [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]]\n",
    "gamma_range= [2**i for i in [-15, -13, -11, -9, -7, -5, -3, -1, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_breast_cancer(y_true, y_pred):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "    FN = CM[1][0]\n",
    "    FP = CM[0][1]\n",
    "    costBC=((-1*((228.35*FP)+(2850000*FN))))\n",
    "    return costBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    nilai=(TN/(FP+TN))\n",
    "    return nilai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_score(y_true, y_pred):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    specificity=(TN/(FP+TN))\n",
    "    sensitivity=(TP/(TP+FN))\n",
    "    accuracy=((TP+TN)/(TP+FP+TN+FN))\n",
    "    costBC=((-1*((228.35*FP)+(2850000*FN))))\n",
    "    return [specificity, sensitivity, accuracy, costBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_custom_scorer=make_scorer(cost_breast_cancer, greater_is_better=True)\n",
    "score_specificity=make_scorer(specificity, greater_is_better=True)\n",
    "output_scoring=make_scorer(output_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for make_scorer(cost_breast_cancer)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.125, 'kernel': 'rbf', 'C': 0.5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-44771794.872 (+/-4444027.676) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-5164239.672 (+/-6631463.620) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-1717536.042 (+/-2789393.112) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-852976.889 (+/-2610192.197) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-641.137 (+/-860.823) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 2, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 8, 'kernel': 'rbf', 'C': 0.03125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 0.125}\n",
      "-41355448.718 (+/-7731077.592) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-5444367.877 (+/-7378615.825) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-2283813.886 (+/-4252853.253) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-1145123.077 (+/-2794535.107) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-852931.024 (+/-2610154.097) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-732.379 (+/-811.303) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 0.125}\n",
      "-1186.639 (+/-733.105) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 0.125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 2, 'kernel': 'rbf', 'C': 0.125}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 8, 'kernel': 'rbf', 'C': 0.125}\n",
      "-41075320.513 (+/-8118548.696) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 0.5}\n",
      "-5444367.877 (+/-7378615.825) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-2576121.579 (+/-4733000.928) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-2003708.126 (+/-3648246.553) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-1145123.077 (+/-2794535.107) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-852907.603 (+/-2610184.689) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-595.271 (+/-795.426) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 0.5}\n",
      "-1302.766 (+/-795.328) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 0.5}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 2, 'kernel': 'rbf', 'C': 0.5}\n",
      "-47329487.179 (+/-2784178.556) for {'gamma': 8, 'kernel': 'rbf', 'C': 0.5}\n",
      "-5444367.877 (+/-7378615.825) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 2}\n",
      "-2576121.579 (+/-4733000.928) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 2}\n",
      "-2003708.126 (+/-3648246.553) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 2}\n",
      "-1431295.649 (+/-3827386.808) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 2}\n",
      "-1139033.334 (+/-3784571.430) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 2}\n",
      "-1437499.080 (+/-3845458.834) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 2}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 2}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 2}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 2}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 2}\n",
      "-2576121.579 (+/-4733000.928) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 8}\n",
      "-2003708.126 (+/-3648246.553) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 8}\n",
      "-1711423.854 (+/-4550640.464) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 8}\n",
      "-1419138.606 (+/-4586623.309) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 8}\n",
      "-2015955.923 (+/-4462935.579) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 8}\n",
      "-2862544.457 (+/-4409070.456) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 8}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 8}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 8}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 8}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 8}\n",
      "-2003708.126 (+/-3648246.553) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 32}\n",
      "-1711423.854 (+/-4550640.464) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 32}\n",
      "-1419138.606 (+/-4586623.309) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 32}\n",
      "-1431341.026 (+/-3827455.551) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 32}\n",
      "-2582324.521 (+/-5937756.087) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 32}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 32}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 32}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 32}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 32}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 32}\n",
      "-1711423.854 (+/-4550640.464) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 128}\n",
      "-1419116.162 (+/-4586539.508) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 128}\n",
      "-1419138.606 (+/-4586623.309) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 128}\n",
      "-2576212.333 (+/-5930966.737) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 128}\n",
      "-4007393.319 (+/-5790027.281) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 128}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 128}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 128}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 128}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 128}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 128}\n",
      "-1711423.854 (+/-4550640.464) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 512}\n",
      "-1419138.606 (+/-4586623.309) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 512}\n",
      "-1711469.231 (+/-4550743.335) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 512}\n",
      "-3715063.670 (+/-5115312.477) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 512}\n",
      "-4853867.678 (+/-5121088.269) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 512}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 512}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 512}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 512}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 512}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 512}\n",
      "-1711446.299 (+/-4550719.160) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 2048}\n",
      "-1419138.606 (+/-4586623.309) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 2048}\n",
      "-2862430.282 (+/-6224065.762) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 2048}\n",
      "-4555447.798 (+/-4551929.341) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 2048}\n",
      "-4853867.678 (+/-5121088.269) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 2048}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 2048}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 2048}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 2048}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 2048}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 2048}\n",
      "-1711468.743 (+/-4550797.858) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 8192}\n",
      "-1711469.231 (+/-4550743.335) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 8192}\n",
      "-4281386.403 (+/-5236620.838) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 8192}\n",
      "-5688163.038 (+/-6224027.522) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 8192}\n",
      "-4853867.678 (+/-5121088.269) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 8192}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 8192}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 8192}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 8192}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 8192}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 8192}\n",
      "-1711446.299 (+/-4550777.830) for {'gamma': 3.0517578125e-05, 'kernel': 'rbf', 'C': 32768}\n",
      "-2862430.282 (+/-6224065.762) for {'gamma': 0.0001220703125, 'kernel': 'rbf', 'C': 32768}\n",
      "-5682073.294 (+/-7613535.826) for {'gamma': 0.00048828125, 'kernel': 'rbf', 'C': 32768}\n",
      "-5408012.388 (+/-5368065.955) for {'gamma': 0.001953125, 'kernel': 'rbf', 'C': 32768}\n",
      "-4853867.678 (+/-5121088.269) for {'gamma': 0.0078125, 'kernel': 'rbf', 'C': 32768}\n",
      "-3148762.406 (+/-4727417.044) for {'gamma': 0.03125, 'kernel': 'rbf', 'C': 32768}\n",
      "-572893.085 (+/-2283874.304) for {'gamma': 0.125, 'kernel': 'rbf', 'C': 32768}\n",
      "-937.796 (+/-692.059) for {'gamma': 0.5, 'kernel': 'rbf', 'C': 32768}\n",
      "-1735.558 (+/-622.068) for {'gamma': 2, 'kernel': 'rbf', 'C': 32768}\n",
      "-2948.057 (+/-689.987) for {'gamma': 8, 'kernel': 'rbf', 'C': 32768}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_range,\n",
    "                     'C': C_range},]\n",
    "\n",
    "scores = [my_custom_scorer]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf2 = GridSearchCV(svc, tuned_parameters, cv=10,\n",
    "                       scoring=my_custom_scorer)\n",
    "    clf2.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf2.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf2.cv_results_['mean_test_score']\n",
    "    stds = clf2.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf2.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cost obtained: -595.2713675213676\n",
      "Parameters:\n",
      "\tgamma: 0.125\n",
      "\tkernel: rbf\n",
      "\tC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score cost obtained: {0}\".format(clf2.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in clf2.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.125, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestSVC=SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.125, kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.125, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestSVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "scoring must return a number, got [0.90322580645161288, 1.0, 0.9375, -685.04999999999995] (<class 'list'>) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-735f7466c09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbestSVC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0moutput_scoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         raise ValueError(\"scoring must return a number, got %s (%s) instead.\"\n\u001b[1;32m--> 298\u001b[1;33m                          % (str(score), type(score)))\n\u001b[0m\u001b[0;32m    299\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: scoring must return a number, got [0.90322580645161288, 1.0, 0.9375, -685.04999999999995] (<class 'list'>) instead."
     ]
    }
   ],
   "source": [
    "scores1=cross_val_score(bestSVC,X_train,y_train,cv=10,scoring= output_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cost: 0.9139 (+/- 0.1163)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores1.mean(), scores1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores2=cross_val_score(bestSVC,X_train,y_train,cv=10,scoring=my_custom_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cost: -593.7100 (+/- 796.2837)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores3=cross_val_score(bestSVC,X_train,y_train,cv=10,scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cost: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores3.mean(), scores3.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores4=cross_val_score(bestSVC,X_train,y_train,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cost: 0.9446 (+/- 0.0743)\n"
     ]
    }
   ],
   "source": [
    "print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores4.mean(), scores4.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\annisa\\anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=RAND_SEED_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "# Tuning hyper-parameters for make_scorer(cost_breast_cancer)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 10, 'reg_lambda': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.5, 'scale_pos_weight': 1.0, 'reg_alpha': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-1711445.323 (+/-3784255.368) for {'n_estimators': 10, 'reg_lambda': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.5, 'scale_pos_weight': 1.0, 'reg_alpha': 0.001}\n",
      "-1991528.639 (+/-4444425.729) for {'n_estimators': 20, 'reg_lambda': 1.0, 'subsample': 0.5, 'colsample_bytree': 0.5, 'scale_pos_weight': 0.66666666666666674, 'reg_alpha': 5.0}\n",
      "-7697549.585 (+/-8096019.022) for {'n_estimators': 30, 'reg_lambda': 0.0, 'subsample': 0.8, 'colsample_bytree': 0.6, 'scale_pos_weight': 0.11111111111111116, 'reg_alpha': 0.005}\n",
      "-2277746.587 (+/-3426531.765) for {'n_estimators': 50, 'reg_lambda': 0.001, 'subsample': 0.7, 'colsample_bytree': 0.8, 'scale_pos_weight': 1.0, 'reg_alpha': 0.0}\n",
      "-47329487.179 (+/-2784178.556) for {'n_estimators': 10, 'reg_lambda': 5.0, 'subsample': 0.8, 'colsample_bytree': 0.8, 'scale_pos_weight': 0.0, 'reg_alpha': 5.0}\n",
      "-2844138.606 (+/-4416814.252) for {'n_estimators': 10, 'reg_lambda': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.6, 'scale_pos_weight': 0.88888888888888884, 'reg_alpha': 0.001}\n",
      "-4829372.084 (+/-6275786.404) for {'n_estimators': 30, 'reg_lambda': 0.001, 'subsample': 0.7, 'colsample_bytree': 0.9, 'scale_pos_weight': 0.44444444444444442, 'reg_alpha': 10.0}\n",
      "-2844115.674 (+/-4416991.690) for {'n_estimators': 50, 'reg_lambda': 0.0, 'subsample': 0.5, 'colsample_bytree': 0.7, 'scale_pos_weight': 1.0, 'reg_alpha': 0.05}\n",
      "-2283836.331 (+/-4269036.647) for {'n_estimators': 20, 'reg_lambda': 0.0, 'subsample': 0.7, 'colsample_bytree': 0.6, 'scale_pos_weight': 0.77777777777777779, 'reg_alpha': 0.001}\n",
      "-2277746.587 (+/-3426606.437) for {'n_estimators': 30, 'reg_lambda': 10.0, 'subsample': 0.7, 'colsample_bytree': 0.5, 'scale_pos_weight': 0.55555555555555558, 'reg_alpha': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters ={'n_estimators': [10,20,30,50],\n",
    "                    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.],\n",
    "                    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.],\n",
    "                    'reg_alpha': [0., 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1., 5., 10.],\n",
    "                    'reg_lambda': [0., 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1., 5., 10.],\n",
    "                    'scale_pos_weight': np.linspace(1., (y_train == 2).sum() / y_train.sum(), 10)\n",
    "                   }    \n",
    "\n",
    "                  \n",
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}\n",
    "scores = [my_custom_scorer]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = RandomizedSearchCV(estimator=XGBClassifier(**params_fixed, seed=RAND_SEED_TUNING),\n",
    "    param_distributions=tuned_parameters, cv=cv, scoring=my_custom_scorer)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cost obtained: -1711445.3228632482\n",
      "Parameters:\n",
      "\tn_estimators: 10\n",
      "\treg_lambda: 0.01\n",
      "\tsubsample: 0.7\n",
      "\tcolsample_bytree: 0.5\n",
      "\tscale_pos_weight: 1.0\n",
      "\treg_alpha: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score cost obtained: {0}\".format(clf.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in clf.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=10, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.001, reg_lambda=0.01,\n",
       "       scale_pos_weight=1.0, seed=84, silent=1, subsample=0.7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestXGB=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=10, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0.001, reg_lambda=0.01,\n",
    "       scale_pos_weight=1.0, seed=84, silent=1, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=10, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.001, reg_lambda=0.01,\n",
       "       scale_pos_weight=1.0, seed=84, silent=1, subsample=0.7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestXGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9668 (+/- 0.0422)\n",
      "Accuracy: 0.9657 (+/- 0.0393)\n",
      "Recall: 0.9640 (+/- 0.0790)\n",
      "Score cost: -1710228.3500 (+/- 3780952.2720)\n"
     ]
    }
   ],
   "source": [
    "scores1=cross_val_score(bestXGB,X_train,y_train,cv=cv,scoring=score_specificity)\n",
    "print(\"Specificity: %0.4f (+/- %0.4f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "scores2=cross_val_score(bestXGB,X_train,y_train,cv=cv,scoring='accuracy')\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores2.mean(), scores2.std() * 2))\n",
    "scores3=cross_val_score(bestXGB,X_train,y_train,cv=cv,scoring='recall')\n",
    "print(\"Recall: %0.4f (+/- %0.4f)\" % (scores3.mean(), scores3.std() * 2))\n",
    "scores4=cross_val_score(bestXGB,X_train,y_train,cv=cv,scoring=my_custom_scorer)\n",
    "print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores4.mean(), scores4.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model8():\n",
    "    model8 = Sequential()\n",
    "    model8.add(Dense(10, input_dim=9, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(10, activation='relu'))\n",
    "    model8.add(Dense(1, activation='sigmoid'))\n",
    "    adm = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model8.compile(loss='binary_crossentropy', optimizer=adm, metrics=['accuracy'])\n",
    "    return model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=create_model8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*is ill-defined', append=True)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9599 (+/- 0.0543)\n",
      "Accuracy: 0.9595 (+/- 0.0335)\n",
      "Recall: 0.9683 (+/- 0.0696)\n",
      "Score cost: -1995274.0200 (+/- 1824840.5135)\n",
      "\n",
      "\n",
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.9388 (+/- 0.0493)\n",
      "Accuracy: 0.9616 (+/- 0.0354)\n",
      "Recall: 0.9938 (+/- 0.0187)\n",
      "Score cost: -570456.7000 (+/- 1139885.8788)\n",
      "\n",
      "\n",
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.8860 (+/- 0.0872)\n",
      "Accuracy: 0.9638 (+/- 0.0301)\n",
      "Recall: 0.9895 (+/- 0.0316)\n",
      "Score cost: -1140525.2050 (+/- 2279851.6433)\n",
      "\n",
      "\n",
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.9147 (+/- 0.0528)\n",
      "Accuracy: 0.9210 (+/- 0.0496)\n",
      "Recall: 0.9843 (+/- 0.0346)\n",
      "Score cost: -286187.4200 (+/- 854758.2331)\n",
      "\n",
      "\n",
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.5977 (+/- 0.3704)\n",
      "Accuracy: 0.9234 (+/- 0.0653)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -1507.1100 (+/- 2432.1151)\n",
      "\n",
      "\n",
      "Epochs : 10 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.8072 (+/- 0.1226)\n",
      "Accuracy: 0.7797 (+/- 0.1901)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -2580.3550 (+/- 2901.1236)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9422 (+/- 0.0550)\n",
      "Accuracy: 0.9702 (+/- 0.0304)\n",
      "Recall: 0.9847 (+/- 0.0234)\n",
      "Score cost: -856073.2450 (+/- 1305482.3123)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.9491 (+/- 0.0580)\n",
      "Accuracy: 0.9638 (+/- 0.0357)\n",
      "Recall: 0.9847 (+/- 0.0332)\n",
      "Score cost: -855342.5250 (+/- 1305959.3708)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.9265 (+/- 0.0642)\n",
      "Accuracy: 0.9489 (+/- 0.0346)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -456.7000 (+/- 395.5138)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.9007 (+/- 0.0962)\n",
      "Accuracy: 0.8680 (+/- 0.1622)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -285365.3600 (+/- 855030.4961)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.8605 (+/- 0.1125)\n",
      "Accuracy: 0.8552 (+/- 0.2035)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -286004.7400 (+/- 854817.7531)\n",
      "\n",
      "\n",
      "Epochs : 20 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.8302 (+/- 0.2799)\n",
      "Accuracy: 0.8957 (+/- 0.1197)\n",
      "Recall: 0.9895 (+/- 0.0316)\n",
      "Score cost: -286666.9550 (+/- 854599.4643)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9599 (+/- 0.0441)\n",
      "Accuracy: 0.9595 (+/- 0.0335)\n",
      "Recall: 0.9794 (+/- 0.0345)\n",
      "Score cost: -1710296.8550 (+/- 2280005.7294)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.9549 (+/- 0.0510)\n",
      "Accuracy: 0.9638 (+/- 0.0344)\n",
      "Recall: 0.9905 (+/- 0.0286)\n",
      "Score cost: -1140319.6900 (+/- 1396321.0515)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.9273 (+/- 0.0529)\n",
      "Accuracy: 0.9660 (+/- 0.0289)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -285388.1950 (+/- 855175.1300)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.8731 (+/- 0.2434)\n",
      "Accuracy: 0.9616 (+/- 0.0366)\n",
      "Recall: 0.9821 (+/- 0.0358)\n",
      "Score cost: -1598.4500 (+/- 2211.5789)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.8866 (+/- 0.1817)\n",
      "Accuracy: 0.9340 (+/- 0.0649)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -5417192.1600 (+/- 16244269.4620)\n",
      "\n",
      "\n",
      "Epochs : 50 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.7793 (+/- 0.3574)\n",
      "Accuracy: 0.8904 (+/- 0.1028)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -2603.1900 (+/- 2778.3730)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9351 (+/- 0.0707)\n",
      "Accuracy: 0.9574 (+/- 0.0343)\n",
      "Recall: 0.9847 (+/- 0.0234)\n",
      "Score cost: -285274.0200 (+/- 855137.0649)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.9583 (+/- 0.0486)\n",
      "Accuracy: 0.9510 (+/- 0.0343)\n",
      "Recall: 0.9764 (+/- 0.0303)\n",
      "Score cost: -285365.3600 (+/- 855334.9526)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.9473 (+/- 0.0434)\n",
      "Accuracy: 0.9298 (+/- 0.0830)\n",
      "Recall: 0.9895 (+/- 0.0316)\n",
      "Score cost: -570479.5350 (+/- 1140045.7215)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.8529 (+/- 0.2213)\n",
      "Accuracy: 0.9553 (+/- 0.0336)\n",
      "Recall: 0.9854 (+/- 0.0223)\n",
      "Score cost: -286210.2550 (+/- 854752.4814)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.9385 (+/- 0.0574)\n",
      "Accuracy: 0.9104 (+/- 0.1259)\n",
      "Recall: 0.8941 (+/- 0.2986)\n",
      "Score cost: -571233.0900 (+/- 1139499.8128)\n",
      "\n",
      "\n",
      "Epochs : 100 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.7536 (+/- 0.3809)\n",
      "Accuracy: 0.9148 (+/- 0.0897)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -285411.0300 (+/- 855015.2830)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9438 (+/- 0.0555)\n",
      "Accuracy: 0.9617 (+/- 0.0434)\n",
      "Recall: 0.9847 (+/- 0.0332)\n",
      "Score cost: -1140981.9050 (+/- 1890194.9524)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.9529 (+/- 0.0501)\n",
      "Accuracy: 0.9532 (+/- 0.0340)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "Score cost: -855365.3600 (+/- 1306193.5443)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.9446 (+/- 0.0483)\n",
      "Accuracy: 0.9573 (+/- 0.0383)\n",
      "Recall: 0.9811 (+/- 0.0299)\n",
      "Score cost: -2280296.8550 (+/- 2792478.9258)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.9246 (+/- 0.0621)\n",
      "Accuracy: 0.9617 (+/- 0.0378)\n",
      "Recall: 0.9847 (+/- 0.0234)\n",
      "Score cost: -285433.8650 (+/- 855007.6754)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.8453 (+/- 0.2854)\n",
      "Accuracy: 0.8691 (+/- 0.1912)\n",
      "Recall: 0.9842 (+/- 0.0337)\n",
      "Score cost: -855456.7000 (+/- 1824890.4705)\n",
      "\n",
      "\n",
      "Epochs : 200 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.9337 (+/- 0.0580)\n",
      "Accuracy: 0.8000 (+/- 0.2658)\n",
      "Recall: 0.8947 (+/- 0.2987)\n",
      "Score cost: -286621.2850 (+/- 854614.8496)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 2})\n",
      "Specificity: 0.9599 (+/- 0.0543)\n",
      "Accuracy: 0.8787 (+/- 0.1874)\n",
      "Recall: 0.9733 (+/- 0.0269)\n",
      "Score cost: -1995411.0300 (+/- 2565035.5530)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 4})\n",
      "Specificity: 0.8536 (+/- 0.2877)\n",
      "Accuracy: 0.9617 (+/- 0.0444)\n",
      "Recall: 0.9847 (+/- 0.0332)\n",
      "Score cost: -1140296.8550 (+/- 1890434.8394)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 8})\n",
      "Specificity: 0.8601 (+/- 0.2886)\n",
      "Accuracy: 0.9212 (+/- 0.1165)\n",
      "Recall: 0.8947 (+/- 0.2987)\n",
      "Score cost: -1140365.3600 (+/- 1396190.5579)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 16})\n",
      "Specificity: 0.9529 (+/- 0.0536)\n",
      "Accuracy: 0.8233 (+/- 0.2490)\n",
      "Recall: 0.9847 (+/- 0.0234)\n",
      "Score cost: -5985388.1950 (+/- 15158537.8220)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 32})\n",
      "Specificity: 0.8629 (+/- 0.2909)\n",
      "Accuracy: 0.8739 (+/- 0.1933)\n",
      "Recall: 0.9854 (+/- 0.0223)\n",
      "Score cost: -6558082.7250 (+/- 18733207.9918)\n",
      "\n",
      "\n",
      "Epochs : 500 & Class Weight : {0: 1.0, 1: 64})\n",
      "Specificity: 0.6620 (+/- 0.4371)\n",
      "Accuracy: 0.7223 (+/- 0.2858)\n",
      "Recall: 0.9000 (+/- 0.3000)\n",
      "Score cost: -855456.7000 (+/- 1306133.7653)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = [10, 20, 50, 100, 200, 500]\n",
    "class_weight = [{0 : 1., 1: 2},\n",
    "                {0 : 1., 1: 4},\n",
    "                {0 : 1., 1: 8},\n",
    "                {0 : 1., 1: 16},\n",
    "                {0 : 1., 1: 32},\n",
    "                {0 : 1., 1: 64}]\n",
    "results=[]\n",
    "model.load_weights('my_model_weights.h5')\n",
    "\n",
    "for epochs_idx in range(len(epochs)):\n",
    "  for class_weight_idx in range(len(class_weight)):\n",
    "    param1 = epochs[epochs_idx]\n",
    "    param2 = class_weight[class_weight_idx]\n",
    "    bestmodelNN = KerasClassifier(build_fn=create_model8, epochs= param1, class_weight = param2, verbose=0)\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    print(\"Epochs : %r & Class Weight : %r)\" % (param1, param2))\n",
    "    scores1=cross_val_score(bestmodelNN,X_train.as_matrix(),y_train,cv=10,scoring=score_specificity)\n",
    "    print(\"Specificity: %0.4f (+/- %0.4f)\" % (scores1.mean(), scores1.std() ))\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    scores2=cross_val_score(bestmodelNN,X_train.as_matrix(),y_train,cv=10,scoring='accuracy')\n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores2.mean(), scores2.std() ))\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    scores3=cross_val_score(bestmodelNN,X_train.as_matrix(),y_train,cv=10,scoring='recall')\n",
    "    print(\"Recall: %0.4f (+/- %0.4f)\" % (scores3.mean(), scores3.std() ))\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    scores4=cross_val_score(bestmodelNN,X_train.as_matrix(), y_train, cv=10, scoring=my_custom_scorer)\n",
    "    print(\"Score cost: %0.4f (+/- %0.4f)\" % (scores4.mean(), scores4.std() ))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_class_weight = {0: 1.0, 1: 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestmodelNN_test = KerasClassifier(build_fn=create_model8, epochs= 20, class_weight = best_class_weight, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9419 (+/- 0.0895)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "\n",
      "\n",
      "Specificity: 0.9265 (+/- 0.1390)\n",
      "Recall: 0.9952 (+/- 0.0286)\n",
      "\n",
      "\n",
      "Specificity: 0.9222 (+/- 0.1428)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "\n",
      "\n",
      "Specificity: 0.9345 (+/- 0.1291)\n",
      "Recall: 0.9952 (+/- 0.0286)\n",
      "\n",
      "\n",
      "Specificity: 0.9302 (+/- 0.1065)\n",
      "Recall: 0.9955 (+/- 0.0273)\n",
      "\n",
      "\n",
      "Specificity: 0.9420 (+/- 0.0989)\n",
      "Recall: 0.9905 (+/- 0.0571)\n",
      "\n",
      "\n",
      "Specificity: 0.9210 (+/- 0.1050)\n",
      "Recall: 0.9947 (+/- 0.0316)\n",
      "\n",
      "\n",
      "Specificity: 0.9521 (+/- 0.1015)\n",
      "Recall: 0.9900 (+/- 0.0402)\n",
      "\n",
      "\n",
      "Specificity: 0.9172 (+/- 0.1240)\n",
      "Recall: 0.9847 (+/- 0.0468)\n",
      "\n",
      "\n",
      "Specificity: 0.9357 (+/- 0.1184)\n",
      "Recall: 1.0000 (+/- 0.0000)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*is ill-defined', append=True)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "for i in range(10):\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    scores1=cross_val_score(bestmodelNN_test, X_train.as_matrix(),y_train,cv=10,scoring=score_specificity)\n",
    "    print(\"Specificity: %0.4f (+/- %0.4f)\" % (scores1.mean(), scores1.std()*2))\n",
    "    model.load_weights('my_model_weights.h5')\n",
    "    scores3=cross_val_score(bestmodelNN_test, X_train.as_matrix(),y_train,cv=10,scoring='recall')\n",
    "    print(\"Recall: %0.4f (+/- %0.4f)\" % (scores3.mean(), scores3.std()*2))\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
